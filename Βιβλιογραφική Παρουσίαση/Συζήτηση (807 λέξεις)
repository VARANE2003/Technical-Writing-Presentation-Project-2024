Ο 21οςαιώνας είναι αυτός που θα μείνει στην ιστορία ως το σημείο καμπής του ανθρώπινου πολιτισμού. Ως ο αιώνας που οι αλγόριθμοι, η τεχνητή νοημοσύνη, η μηχανική μάθηση, τα μεγάλα δεδομένα και άλλα τεχνουργήματα της επιστήμης της πληροφορίας οδήγησαν στην ραγδαία πρόοδο όλων των πτυχών της ανθρώπινης δραστηριότητας. Κάθε επαναστατική ιδέα, όμως, ικανή να αλλάξει τον τρόπο ζωής μας, συνοδεύεται και από διαμάχες, κοινωνικές αναδιατάξεις και ηθικά διλλήματα. Οι προαναφερθείσες έννοιες δεν αποτελούν εξαίρεση. Στο παρόν κείμενο θα εξεταστούν ορισμένα ήδη ερευνημένα ζητήματα τα οποία επιφέρει η ψηφιακή εποχή.
    Ξεκινώντας, θα αποτελούσε παράλειψη να μη γίνει αναφορά στις φιλοσοφικές προεκτάσεις της ψηφιοποίησης, καθώς αυτές απειλούν ακόμη και διαχρονικούς θεσμούς, όπως αυτού του κράτους [1]. Σύμφωνα με το Βαγγέλη Παπακωνσταντίνου, πρέπει να εγκαταλείψουμε τον κλασικό ορισμό του κράτους, βλέποντας το ως κοινωνικό συμβόλαιο και να αρχίσουμε να το αντιμετωπίζουμε ως μια πλατφόρμα που εξασφαλίζει τη ροή πληροφορίας ανάμεσα στα άτομα που υπάγονται σε αυτό, καθώς η πληροφορία πλέον, αποτελεί την κύρια επιδίωξη του ανθρώπου.
    Η πληροφορία σε ψηφιακή μορφή, στον μεγαλύτερο όγκο της δεν είναι τίποτε άλλο παρά μεγάλα δεδομένα. Δεδομένα μεγέθους τέτοιου που ένα απλό μηχάνημα δεν μπορεί ναδιαχειριστεί. Τα δεδομένα αυτά, συλλέγονται και αξιοποιούνται για τη βελτίωση της ζωής μας, αλλά σύμφωνα με το [2], εγείρονται ζητήματα σωστής διαχείρισης και ερμηνείας τους, καθώς και κοινωνικά ζητήματα. Αυτό συμβαίνει διότι η διαχείριση τους γίνεται από «κέντρα πληροφορίας», συμβάλλοντας έτσι στον συγκεντρωτισμό της εξουσίας και στην όξυνση της «πληροφορικής της κυριαρχίας».
Από την άλλη πλευρά, πέρα από την ωμή πληροφορία και τη διαχείριση της, ζητήματα εγείρει και η τεχνητή νοημοσύνη. Στο προσκήνιο βρίσκονται όροι όπως «μιμητικά μοντέλα» [3]. Τεχνουργήματα της τεχνητής νοημοσύνης που προσομοιώνουν τη συμπεριφορά και τις αποφάσεις ανθρώπων. Τέτοια μοντέλα θολώνουν τα όρια ανάμεσα σε μηχανική και ανθρώπινη συμπεριφορά και δημιουργούν ζητήματα εξαπάτησης, όπως προκύπτει τον τελευταίο καιρό από τα deepfakes. Αυτά θα μπορούσαν να χρησιμοποιηθούν εκ μέρος ατόμων από τρίτους, με σκοπό τη δυσφήμιση. Επιπρόσθετα αν ξεπεράσουν τιςανθρώπινες δυνατότητες -που σε κάποιο βαθμό, ήδη το κάνουν- απαξιώνεται η ανθρώπινη προσπάθεια και ελλοχεύει ο κίνδυνος αντικατάστασης του ανθρώπου από μιμητικά μοντέλα.
Μία άλλη σκοτεινή πτυχή της ψηφιακής εποχής είναι η παρακολούθηση και η άκρατη συλλογή προσωπικών δεδομένων, όπως και ο τρόπος που αυτά χρησιμοποιούνται. Ήδη μέσω των συσκευών μας, εταιρείες όπως, Google, Metaκαι άλλες έχουν πρόσβαση σε προσωπικά μας δεδομένα. Το πρόβλημα δημιουργείται από τη λανθασμένη χρήση των δεδομένων αυτών. Η κατοχή των δεδομένων καθιστά παντοδύναμο αυτόν που τα ελέγχει, και του δίνει τη δυνατότητα να ελέγξει σε κάποιο βαθμό τα άτομα για τα οποία κατέχει πληροφορίες. Έτσι οδηγούμαστε στο παράδειγμα της Κίνας, όπου οι άνθρωποι αξιολογούνται με ψηφιακά socialcreditscoresκαι βάσει αυτών ελέγχεται η πρόσβασή τους σε υπηρεσίες. Τον όρο «Überveillance» [4], δηλαδή Μεταπαρακολούθηση, χρησιμοποιεί ο R. Clarkeγια την παραπάνω κατάσταση, περιγράφοντας την ως την συνεχή παρακολούθηση ατόμων και την εκτενή παραβίαση της ιδιοτικότητας.
    Το πρόβλημα της παρακολούθησης όμως δεν είναι μόνο ηθικό, σχετικό με τον έλεγχο των ανθρώπων, αλλά και νομικό, καθώς η έννομη χρήση των δεδομένων μας δεν είναι εξασφαλισμένη. Αυτό αποδεικνύεται επανειλημμένα από σκάνδαλα όπως το  «Facebook–Analytica» [5], όπουη εταιρεία CambridgeAnalyticaχρησιμοποίησε χωρίς τη συγκατάθεσή τους, τα δεδομένα 87 εκατομμυρίων χρηστών του Facebookγια να κατασκευάσει ψυχολογικά προφίλ και να εμφανίζει εξατομικευμένες πολιτικές διαφημίσεις. Φημολογείται μάλιστα πως τα αποτελέσματα των αμερικανικών εκλογών του 2016 επηρεάστηκαν από το σκάνδαλο αυτό.
Ένα ακόμη σημείο, άξιο αναφοράς, είναι το γεγονός πως τα ζητήματα της ψηφιακής εποχής, δεν αφορούν μόνο τη λανθασμένη χρήση αλγορίθμων και δεδομένων, αλλά και εγγενή προβλήματα των ίδιων των αλγορίθμων που χρησιμοποιούμε [6]. Οι αλγόριθμοί μας δεν είναι ηθικά ουδέτεροι και συχνά παρουσιάζουν πόλωση προς κάποια κατεύθυνση. Παραδείγματα είναι η συχνότερη διαφήμιση υψηλόμισθων θέσεων εργασίας σε τομείς της τεχνολογίας σε άνδρες, παρά σε γυναίκες ή το γεγονός πως αλγόριθμοι πρόβλεψης που διαχειρίζονται δεδομένα σχετικά με την υγεία ασθενών, οξύνουν προβλήματα, όπως της καλύτερης μεταχείρισης λευκών ασθενών έναντι μαύρων. Ακόμη κάποιαπαραδείγματααποτελούνη εύρεση συσχετίσεων σε δεδομένα, εκεί που δεν υπάρχουν από συσχετιστικούς αλγόριθμους, τα μη αντιπροσωπευτικά trainingsets σε αλγορίθμους μηχανικής μάθησης και η αδυναμία κατανόησης δυσνόητα γραμμένων αλγορίθμων. Παρά τις προαναφερθείσες αδυναμίες των αλγορίθμων, ειδικοί συχνά πέφτουν στην παγίδα της «προκατάληψης της αυτοματοποίησης», αγνοώντας την εμπειρία τους και εναποθέτοντας τυφλά την εμπιστοσύνη τους στα «αλάνθαστα» μηχανήματα.
Συμπερασματικά μπορούμε να αποφανθούμε πως τα δεδομένα και οι αλγόριθμοι αποτελούν οντότητες με μεγάλη δύναμη, ικανά να επηρεάσουν τις ζωές μας. Το πως αυτά θα τις επηρεάσουν είναι στο χέρι μας. Για να παραφράσουμε και τους K. Crawford, K. Miltner, και M. L. Gray του [2]: Τα δεδομένα πρέπει να αντιμετωπίζονται ως πόρος για να καταναλώνεται και ως φυσική δύναμη προς έλεγχο. Όπως κάθε άλλη φυσική δύναμη πρέπει να χαλιναγωγείται. Κλείνοντας, χρέος μας είναι να μην ξεχνάμε πως η τεχνολογία πρέπει να είναι στην υπηρεσία μας, και όχι εμείς στη δική της. Περεταίρω ενδιαφέρουσες πηγές για το θέμα είναι διαθέσιμες [7], [8], [9].
